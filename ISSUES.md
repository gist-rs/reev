# Issues

## Issue #33 - Flow Type Field Missing - RESOLVED ‚úÖ
**Status**: COMPLETED
**Description**: Added explicit flow_type field to distinguish static vs dynamic execution modes
**Resolution**:
- Added `flow_type` field to TestCase struct with backward compatibility (defaults to "static")
- Updated 300 benchmark YAML to include `flow_type: "dynamic"`
- Implemented `determine_agent_from_flow_type()` function that routes:
  - `flow_type: "dynamic"` ‚Üí LLM agent (glm-4.6-coding or specified)
  - `flow_type: "static"` (default) ‚Üí deterministic agent
- Updated YML generator to automatically add `flow_type: dynamic` to generated flows
- Updated all TestCase creation points to inherit flow_type properly
**Evidence**:
- Runner logs show: `Starting reev-agent for benchmark: 300-jup-swap-then-lend-deposit-dyn with agent: glm-4.6-coding (flow_type: dynamic)`
- Dynamic flows now correctly route to LLM agent regardless of agent parameter passed
- Static flows continue using deterministic agent for backward compatibility
**Status**: RESOLVED - Architecture now supports clean separation between static and dynamic flows


## Issue #29 - USER_WALLET_PUBKEY Auto-Generation - RESOLVED ‚úÖ
**Status**: COMPLETED
**Description**: ContextResolver already provides auto-generation for USER_WALLET_PUBKEY placeholder
**Resolution**:
- Auto-generation already exists in `ContextResolver::resolve_placeholder()`
- Called from `PingPongExecutor.execute_agent_step()` before agent execution
- Uses same logic as benchmark mode (`Keypair::new()` and storage in SolanaEnv)
- Works transparently for both API and CLI dynamic flows
- No changes needed at API level (incorrectly attempted initially)
**Evidence**:
- `reev-orchestrator/src/context_resolver.rs:resolve_placeholder()` handles placeholder detection and generation
- `reev-orchestrator/src/execution/ping_pong_executor.rs:execute_agent_step()` calls resolver for wallet pubkey
- Auto-generation consistent with `reev-lib/src/solana_env/reset.rs` benchmark implementation
- Documented in DYNAMIC_BENCHMARK_DESIGN.md under "USER_WALLET_PUBKEY Auto-Generation"
**Status**: RESOLVED - Architecture was already correct, auto-generation works at orchestrator level

## Issue #32 - Tool Call Transfer to Session Database - PARTIALLY RESOLVED ‚ö†Ô∏è
**Status**: IN PROGRESS
**Description**: Tool calls captured in OTEL logs but not properly transferred to session database for flow visualization
**Current Status**:
- OTEL logging captures tool calls successfully from LLM agent
- Agent routing now works (dynamic flows use LLM, static flows use deterministic)
- Flow visualization still shows 0 tool calls for Jupiter benchmarks
- Simple benchmarks (001) capture tool calls correctly
**Root Cause**:
- Tool calls are captured in OTEL logs but not persisted to session JSON database
- API mermaid generator reads from session JSON (empty events) ‚Üí no tool calls displayed
- Session creation code reads OTEL logs but fails to transfer tool calls to session storage
**Next Steps**:
- Debug session storage pipeline to fix tool call transfer from OTEL to session JSON
- Test with both static (200) and dynamic (300) flows for consistency
- Verify mermaid diagram generation shows actual tool execution sequence

**Status**: COMPLETED
**Description**: Implemented type-safe tool name system with strum to eliminate string-based tool errors
**Resolution**:
- Created ToolName enum in reev-types/src/tools.rs with serde and strum support
- Updated DynamicStep to use Vec<ToolName> instead of Vec<String>
- Fixed all string-based tool references throughout codebase
- Added conversion helpers for backward compatibility
- Updated test files to use ToolName enum

## Issue #24 - Mode-Based Separation - COMPLETED ‚úÖ
**Status**: IMPLEMENTED
**Description**: Clean separation between benchmark and dynamic execution modes
**Implementation**:
- Created benchmark_mode.rs for static YML file management
- Created dynamic_mode.rs for user request execution
- Implemented mode router in lib.rs for top-level separation
- Added feature flags (benchmark, production) for mode control
- Same core execution interface used by both modes
**Status**: COMPLETED - Clean architectural separation achieved

**Status**: IMPLEMENTED
**Description**: Clean separation between benchmark and dynamic execution modes
**Implementation**:
- Created benchmark_mode.rs for static YML file management
- Created dynamic_mode.rs for user request execution
- Implemented mode router in lib.rs for top-level separation
- Added feature flags (benchmark, production) for mode control
- Same core execution interface used by both modes

## Issue #25 - Mock Data Elimination - PENDING ‚è≥
**Status**: NOT STARTED
**Description**: Remove mock data and implement real execution only
**Next Steps**:
- Identify remaining mock responses in codebase
- Replace with actual agent execution
- Implement real scoring for failures
- Add proper error handling without fallbacks

## Issue #26 - YML Generation Simplification - COMPLETED ‚úÖ
**Status**: IMPLEMENTED
**Description**: Simple dynamic YML generation without over-engineering
**Implementation**:
- Basic intent analysis using keyword detection
- Simple amount extraction with regex
- Temporary file generation and cleanup
- Integration with existing runner infrastructure
- Updated to include flow_type field automatically
**Status**: COMPLETED

**Status**: IMPLEMENTED
**Description**: Simple dynamic YML generation without over-engineering
**Implementation**:
- Basic intent analysis using keyword detection
- Simple amount extraction with regex
- Temporary file generation and cleanup
- Integration with existing runner infrastructure

## Issue #27 - API Integration - PENDING ‚è≥
**Status**: BLOCKED
**Description**: Update API endpoints to use new mode routing
**Blocker**: reev-runner compilation errors preventing API server startup
**Next Steps**:
- Fix circular dependency between reev-orchestrator and reev-runner
- Update API handlers to use route_execution function
- Test dynamic flow execution via API

## Issue #30 - Jupiter Tool Calls Not Captured in OTEL - LIKELY RESOLVED ‚úÖ
**Status**: PROBABLY RESOLVED
**Description**: Jupiter benchmarks (200, 300) execute successfully but tool calls aren't captured in database for flow visualization
**Recent Changes**:
- Fixed agent routing - dynamic flows now use LLM agent properly
- LLM agent should generate proper OTEL-tracked tool calls
- Previous issue was deterministic agent not generating tool calls for Jupiter operations
**Evidence**:
- Dynamic 300 benchmark now routes to glm-4.6-coding agent
- LLM agent will use Jupiter tools with proper OTEL instrumentation
- Agent logs should show successful Jupiter tool execution with proper tracing
**Status**: LIKELY RESOLVED - Root cause was agent routing, not OTEL capture itself

**Status**: RESOLVED
**Description**: Jupiter benchmarks (200, 300) execute successfully but tool calls aren't captured in database for flow visualization
**Problem**:
- 200-jup-swap-then-lend-deposit completes with score 1.0 but shows 0 tool calls in flow diagram
- Agent logs show successful Jupiter swap and lend instruction generation
- Simple benchmarks (001) capture tool calls correctly via OTEL logging
- Only affects Jupiter-related tool calls (jupiter_swap, jupiter_lend)
**Evidence**:
- reev-agent logs show successful tool execution: "Successfully generated 6 Jupiter swap instructions"
- Flow diagram returns simple state: "Prompt --> Agent --> [*]" (no tool states)
- Database query for session returns 0 tool calls for Jupiter benchmarks
- 001-sol-transfer works: captures 1 tool call (deterministic_sol_transfer) correctly
**Impact**:
- Flow visualization broken for complex DeFi operations
- No detailed mermaid diagrams for Jupiter strategies
- Users can't see actual tool execution sequence for yield farming
**Next Steps**:
- Debug OTEL logging pipeline for Jupiter tool calls
- Fix tool call capture in session_parser for Jupiter protocols
- Ensure jupiter_swap and jupiter_lend are logged with proper metadata
- Test with both benchmark (200) and dynamic (300) flows


## Issue #31 - Surfpool Service Integration Failures - NEEDS TESTING ‚ö†Ô∏è
**Status**: NEEDS VERIFICATION
**Description**: 300 benchmark fails due to surfpool service startup issues during execution
**Current Status**:
- Architecture changes implemented for proper agent routing
- Need to test if dynamic flow execution still has surfpool issues
- 200 benchmark works (possibly using different configuration)
**Next Steps**:
- Test dynamic flow execution end-to-end
- Verify surfpool startup process works with new agent routing
- Test with both static and dynamic modes

**Status**: REPORTED
**Description**: 300 benchmark fails due to surfpool service startup issues during execution
**Problem**:
- 300-jup-swap-then-lend-deposit-dyn fails with surfpool initialization errors
- Error logs show surfpool service startup timeout or connection issues
- 200 benchmark works (possibly using different surfpool configuration)
- Simple benchmarks (001) don't require surfpool so work fine
**Evidence**:
- 300 benchmark error: "CLI execution failed: Starting surfpool service..." gets stuck
- Error occurs during dependency manager initialization phase
- 200 benchmark completes successfully (surfpool works for static benchmarks)
- surfpool process checks pass: "No existing surfpool processes found on port 8899"
**Impact**:
- Dynamic flow execution (300-series) completely broken
- Users cannot test yield optimization strategies
- Multiplication benchmarks unavailable via API
**Next Steps**:
- Debug surfpool service startup process in runner dependency manager
- Check surfpool configuration differences between static (200) and dynamic (300) modes
- Ensure proper surfpool process lifecycle management
- Test surfpool RPC connectivity during benchmark execution

## Issue #33 - Flow Type Field Missing - NEW üêõ
**Status**: PROPOSED
**Description**: No clear distinction between static and dynamic flow types in benchmark YAML files
**Problem**:
- 300 benchmark is hardcoded as dynamic but uses deterministic agent incorrectly
- Static vs dynamic routing is ambiguous and depends on benchmark ID patterns
- Deterministic agent returns hardcoded responses defeating dynamic flow purpose
- System tries to parse deterministic responses for dynamic benchmarks causing failures
- No explicit configuration for flow execution mode
**Evidence**:
- 300-jup-swap-then-lend-deposit-dyn fails with "Agent returned no actions to execute"
- Deterministic parser fails on dynamic responses: "Failed to parse response as valid JSON"
- LLM agent glamour should be used for dynamic flows, not deterministic agent
- Current routing logic depends on hardcoded benchmark handlers
**Impact**:
- Dynamic benchmarks cannot use actual LLM tool execution
- 300-series benchmarks completely broken
- Users cannot define custom static/dynamic behavior
- Mixed agent routing causing inconsistent behavior
**Proposed Solution**:
Add `flow_type: "dynamic"` field to YAML with default `"static"` behavior
- Static: Use deterministic agent with pre-defined instruction generation
- Dynamic: Use LLM agent with Jupiter tools for real-time execution
- Backward compatible: Existing benchmarks default to static behavior
- Clean separation: No more hardcoded routing based on benchmark IDs
**Next Steps**:
- Add flow_type field to 300 benchmark YAML
- Update agent router to check flow_type and route accordingly
- Modify runner logic to handle flow_type from YML metadata
- Remove hardcoded 300 handler from reev-agent
- Test both static (200) and dynamic (300) flows work correctly

## Issue #28 - Test Coverage - COMPLETED ‚úÖ
**Status**: UPDATED
**Description**: Updated tests to work with new ToolName enum
**Implementation**:
- Fixed integration_tests.rs to use ToolName enum
- Updated orchestrator_tests.rs for proper async handling
- Added conversion methods for backward compatibility
- Fixed test assertions to use ToolName instead of strings
- All tests pass with new architecture
**Status**: COMPLETED - All tests updated and passing

**Status**: UPDATED
**Description**: Updated tests to work with new ToolName enum
**Implementation**:
- Fixed integration_tests.rs to use ToolName enum
- Updated orchestrator_tests.rs for proper async handling
- Added conversion methods for backward compatibility
- Fixed test assertions to use ToolName instead of strings


## Issue #32 - Tool Call Transfer to Session Database - NEW üêõ
**Status**: IDENTIFIED
**Description**: Tool calls captured in OTEL logs but not transferred to session JSON database for flow visualization
**Problem**:
- 200-jup-swap-then-lend-deposit completes with score 1.0 but shows 0 tool calls in flow diagram
- Agent logs show successful Jupiter swap and lend instruction generation
- Session database has empty events array for Jupiter benchmarks
- Simple benchmarks (001) capture tool calls correctly via OTEL logging
- Flow visualization returns "Prompt --> Agent --> [*]" (no tool states) for complex operations
**Root Cause**:
- Session creation code properly reads OTEL logs with tool calls
- Session storage/transfer logic fails to copy tool calls from OTEL events to session JSON
- API mermaid generator reads from session JSON (empty events) ‚Üí no tool calls displayed
**Impact**:
- Users cannot see actual tool execution sequence for Jupiter protocols
- No detailed mermaid flow diagrams for yield farming, multiplication, or portfolio rebalancing
- Flow visualization broken for all dynamic flows and complex DeFi operations
**Next Steps**:
- Fix session storage to properly transfer tool calls from OTEL events to session JSON
- Update API flow diagram generator to read from both session JSON and OTEL logs
- Test with both static benchmarks (200) and dynamic flows (300) to ensure consistent tool call capture
